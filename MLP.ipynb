{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80d4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#23/05/2023 - done with the most basic form of MLP implementation, next: start tuning hyperparameters & improving model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2343a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config Parameters\n",
    "quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.60, 0.70, 0.80, 0.90, 0.95]\n",
    "quantile_pairs = [(0.05, 0.95), (0.10, 0.90), (0.20, 0.80), (0.30, 0.70), (0.40, 0.60)]\n",
    "batch_size, lr, n_epochs = 240, 0.001, 100\n",
    "lag_period, num_features, forecast_horizon = 20, 14, 2\n",
    "num_inputs, num_outputs, num_hidden = lag_period*num_features, (1+len(quantiles))*num_features, 400\n",
    "i_train = 2400\n",
    "i_val = i_train + 800\n",
    "i_test = i_val + 1600 \n",
    "#2400 for training, 800 for validation, 1600 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f340a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load & Split Data\n",
    "data = pd.read_csv(\"/Users/lixiang/Desktop/DeepJMQR Project/data.csv\")\n",
    "alldata = np.array(data)[:,1:].astype(\"float32\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "X = []\n",
    "for i in range(lag_period, len(data)):\n",
    "    X.append(alldata[i-lag_period:i])\n",
    "X = torch.tensor(np.array(X), requires_grad = True)\n",
    "Y = alldata[lag_period+forecast_horizon:]\n",
    "\n",
    "X_train, Y_train = X[:i_train], torch.tensor(Y[:i_train])\n",
    "X_val, Y_val = X[i_train:i_val], Y[i_train:i_val]\n",
    "X_test, Y_test = X[i_val:i_test], Y[i_val:i_test]\n",
    "train_iter = torch.utils.data.DataLoader(list(zip(X_train,Y_train)), batch_size=batch_size, shuffle = True)\n",
    "val_iter = torch.utils.data.DataLoader(list(zip(X_val,Y_val)), batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b17ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation & Loss Functions\n",
    "def tilted_loss(τ, y, ŷ):\n",
    "    #inputs same shape as defined in lossfn, could be tensors/np.array\n",
    "    j = len(τ)\n",
    "    if len(ŷ.shape) == 1:\n",
    "        y, ŷ = y.reshape(-1,j+1), ŷ.reshape(-1,j+1)\n",
    "    loss = 0.0\n",
    "    for i in range(j):\n",
    "        q = τ[i]\n",
    "        r = y[:, i+1] - ŷ[:, i+1]\n",
    "        loss += sum(q*r - r*(r<0))\n",
    "    return loss\n",
    "\n",
    "def lossfn(τ, y, ŷ):\n",
    "    #for ConvLSTM & MLP\n",
    "    #τ: quantile vector of length J\n",
    "    #y, ŷ: observation & prediction, tensors of dim M x (1+J) or 1D tensor of the form [μ q1 q2 q3...] x M\n",
    "    j = len(τ)\n",
    "    if len(ŷ.shape) == 1:\n",
    "        y, ŷ = y.reshape(-1,j+1), ŷ.reshape(-1,j+1)\n",
    "    loss = tilted_loss(τ, y, ŷ)\n",
    "    loss += torch.sum(torch.square(y[:,0]-ŷ[:,0]))\n",
    "    return loss\n",
    "\n",
    "#for evaluation: remember to turn tensors into np.array()\n",
    "def eval_quantiles(lower, upper, preds):\n",
    "    #all inputs are np.array() of same length\n",
    "    icp = np.mean((preds > lower) & (preds < upper))\n",
    "    mil = np.mean(np.maximum(0,upper-lower))\n",
    "    return icp,mil\n",
    "\n",
    "def crossing_loss(τ,ŷ):\n",
    "    #ŷ: np.array() of same shape as defined in lossfn\n",
    "    j = len(τ)\n",
    "    if len(ŷ.shape) == 1:\n",
    "        ŷ = ŷ.reshape(-1,j+1)\n",
    "    loss = 0.0 #crossing loss as defined in the paper\n",
    "    num_cross = 0.0\n",
    "    for i in range(len(ŷ[0,:])-2):\n",
    "        q = ŷ[:,i+1] - ŷ[:,i+2]\n",
    "        loss += np.sum(np.maximum(q,0))\n",
    "        num_cross += np.sum(q>0)\n",
    "    return loss, num_cross\n",
    "\n",
    "def eval_error(y, ŷ):\n",
    "    #y, ŷ: np.array() of same shape M x (1+J) or (1+J) vector\n",
    "    r = np.abs(y-ŷ)\n",
    "    mse = np.mean(r*r)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(r)\n",
    "    return mse, rmse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dd67fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Model\n",
    "net = nn.Sequential(nn.Flatten(), nn.Linear(num_inputs,num_hidden), nn.ReLU(), nn.Linear(num_hidden, num_outputs))\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std = 0.01)\n",
    "net.apply(init_weights)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = lr)\n",
    "def train(model, train_iter, test_iter, quantiles, loss_fn, optimizer, num_epochs = 100):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "    for i, data in enumerate(train_iter):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(quantiles, labels, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        last_loss = loss.item()\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90f255e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 39.2470703125 25.77938461303711 \n",
      "\n",
      "epoch: 2 37.880794525146484 19.175527572631836 \n",
      "\n",
      "epoch: 5 44.876529693603516 12.883186340332031 \n",
      "\n",
      "epoch: 13 39.54420852661133 9.172379493713379 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train Model\n",
    "best_vloss = 1e9\n",
    "for epoch in range(n_epochs):\n",
    "    net.train(True)\n",
    "    avg_loss = train(net, train_iter, val_iter, quantiles, lossfn, optimizer, num_epochs = n_epochs)\n",
    "    net.train(False)\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(val_iter):\n",
    "        vinputs, vlabels = vdata\n",
    "        voutputs =  net(vinputs)\n",
    "        vloss = lossfn(quantiles, vlabels, voutputs)\n",
    "        running_vloss += vloss\n",
    "    avg_vloss = float(running_vloss / (i+1))\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        torch.save(net.state_dict(), \"model_best_state\")\n",
    "        print(\"epoch:\",epoch+1,avg_loss, avg_vloss,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30eac004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossing Loss: (1933.4830589294434, 55200.0)\n",
      "MSE: 0.0009297246 RMSE: 0.030343968 MAE: 0.026575156\n",
      "Tilted loss: 1348.7804559631036\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Errors\n",
    "model = nn.Sequential(nn.Flatten(), nn.Linear(num_inputs,num_hidden), nn.ReLU(), nn.Linear(num_hidden, num_outputs))\n",
    "model.load_state_dict(torch.load(\"model_best_state\"))\n",
    "pred = model(X_val).detach().numpy().reshape(-1,num_features, 1+len(quantiles))\n",
    "print(\"Crossing Loss:\", crossing_loss(quantiles, pred))\n",
    "err = []\n",
    "tloss = 0.0\n",
    "for i in range(1+len(quantiles)):\n",
    "    err.append(eval_error(pred[:,:,i],Y_val))\n",
    "    tloss += tilted_loss(quantiles, Y_val, pred[:,:,i])\n",
    "for pairs in quantile_pairs:\n",
    "    l,u = pairs\n",
    "print(\"MSE:\",np.mean([x[0] for x in err]), \"RMSE:\",np.mean([x[1] for x in err]),\"MAE:\", np.mean([x[2] for x in err]))\n",
    "print(\"Tilted loss:\",tloss)\n",
    "#Test data will be touched after everything is done i.e. tuning hyperparameters & adjusting model architecture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
