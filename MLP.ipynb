{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80d4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from d2l import torch as d2l\n",
    "#23/05/2023 - done with the most basic form of MLP implementation\n",
    "#24/05/2023 - fixed wrong dimensions of inputs in Evaluation & Loss Functions and other bugs, added Dropout & Unflatten layer\n",
    "#25/05/2023 - tested different hyperparameters & model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce2343a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config Parameters\n",
    "quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.60, 0.70, 0.80, 0.90, 0.95]\n",
    "qlen = len(quantiles)\n",
    "i_train = 2400\n",
    "i_val = i_train + 800\n",
    "i_test = i_val + 1600 \n",
    "#2400 for training, 800 for validation, 1600 for testing\n",
    "batch_size, lr, n_epochs, num_iter = 128, 0.002, 100, 30\n",
    "lag_period, num_features, forecast_horizon = 20, 14, 2\n",
    "num_inputs, num_outputs, num_hidden1, num_hidden2 = lag_period*num_features, (1+qlen)*num_features, 200, 200\n",
    "dropout= 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f340a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load & Split Data\n",
    "data = pd.read_csv(\"/Users/lixiang/Desktop/DeepJMQR Project/data.csv\")\n",
    "alldata = np.array(data)[:,1:].astype(\"float32\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "X = []\n",
    "for i in range(lag_period, len(data)):\n",
    "    X.append(alldata[i-lag_period:i])\n",
    "X = torch.tensor(np.array(X), requires_grad = True)\n",
    "Y = alldata[lag_period+forecast_horizon:]\n",
    "\n",
    "X_train, Y_train = X[:i_train], torch.tensor(Y[:i_train])\n",
    "X_val, Y_val = X[i_train:i_val], Y[i_train:i_val]\n",
    "X_test, Y_test = X[i_val:i_test], Y[i_val:i_test]\n",
    "train_iter = torch.utils.data.DataLoader(list(zip(X_train,Y_train)), batch_size=batch_size, shuffle = True)\n",
    "val_iter = torch.utils.data.DataLoader(list(zip(X_val,Y_val)), batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b17ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation & Loss Functions\n",
    "def lossfn(τ, y, ŷ):\n",
    "    #for ConvLSTM & MLP\n",
    "    #τ: quantile vector of length J\n",
    "    #ŷ: prediction, 3D tensor of dim B x M x (1+J)\n",
    "    #y: observation, 2D tensor of dim B x M\n",
    "    #B = batch size or test/val data size\n",
    "    loss = torch.sum(torch.square(y-ŷ[:,:,0]))\n",
    "    for i in range(len(τ)):\n",
    "        q = τ[i]\n",
    "        r = y - ŷ[:,:,i+1]\n",
    "        loss += torch.sum(q*r - r*(r<0))\n",
    "    loss /= y.shape[0]\n",
    "    return loss\n",
    "\n",
    "#for evaluation: remember to turn tensors into np.array()\n",
    "def tilted_loss(τ, y, ŷ):\n",
    "    #y & ŷ: np.array() of same shape as defined in lossfn\n",
    "    loss = 0.0\n",
    "    for i in range(len(τ)):\n",
    "        q = τ[i]\n",
    "        r = y - ŷ[:,:,i+1]\n",
    "        loss += np.sum(q*r - r*(r<0))\n",
    "    loss /= y.shape[0]\n",
    "    return loss\n",
    "def crossing_loss(ŷ):\n",
    "    #ŷ: np.array() of same shape as defined in lossfn\n",
    "    loss = 0.0 #crossing loss as defined in the paper\n",
    "    num_cross = 0.0\n",
    "    for i in range(len(ŷ[0,0,:])-2):\n",
    "        q = ŷ[:,:,i+1] - ŷ[:,:,i+2]\n",
    "        loss += np.sum(np.maximum(q,0))\n",
    "        num_cross += np.sum(q>0)\n",
    "    loss /= ŷ.shape[0]\n",
    "#     num_cross /= ŷ.shape[0]*ŷ.shape[1]*ŷ.shape[2]\n",
    "    return loss, num_cross\n",
    "def eval_quantiles(lower, upper, trues):\n",
    "    #all inputs are np.array of dim B x M\n",
    "    icp = np.mean((trues > lower) & (trues < upper))\n",
    "    mil = np.mean(np.maximum(0,upper-lower))\n",
    "    return icp,mil\n",
    "def eval_error(y, ŷ):\n",
    "    #y, ŷ: np.array() of same shape as defined in lossfn\n",
    "    r = np.abs(y-ŷ[:,:,0])\n",
    "    mse = np.mean(r*r)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(r)\n",
    "    return mse, rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd67fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Model\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std = 0.01)\n",
    "def init():\n",
    "    net = nn.Sequential(nn.Flatten(), \n",
    "                        nn.Linear(num_inputs,num_hidden1),     \n",
    "                        nn.ReLU(),                    \n",
    "                        nn.BatchNorm1d(num_hidden1),\n",
    "                        nn.Dropout(dropout),\n",
    "                        nn.Linear(num_hidden1,num_hidden2),\n",
    "                        nn.ReLU(),\n",
    "#                         nn.BatchNorm1d(num_hidden2),    \n",
    "#                         nn.Dropout(dropout),\n",
    "                        nn.Linear(num_hidden2,num_outputs),\n",
    "                        nn.Unflatten(1,(num_features, (1+qlen))))\n",
    "    net.apply(init_weights)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f255e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "def train(model, train_iter, quantiles, loss_fn, optimizer, num_epochs = 100):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "    for i, data in enumerate(train_iter):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(quantiles, labels, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        last_loss = loss.item()\n",
    "    return last_loss\n",
    "\n",
    "def iter():\n",
    "    best_vloss = 1e9\n",
    "#     animator = d2l.Animator(xlabel = \"epoch\", ylabel = \"loss\", xlim = [1,n_epochs], ylim = [0,1], legend = [\"train\", \"val\"])\n",
    "    for epoch in range(n_epochs):\n",
    "        net.train(True)\n",
    "        avg_loss = train(net, train_iter, quantiles, lossfn, optimizer, num_epochs = n_epochs)\n",
    "        net.train(False)\n",
    "        running_vloss = 0.0\n",
    "        for i, vdata in enumerate(val_iter):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs =  net(vinputs)\n",
    "            vloss = lossfn(quantiles, vlabels, voutputs)\n",
    "            running_vloss += vloss\n",
    "        avg_vloss = float(running_vloss / (i+1))\n",
    "#         if epoch % (n_epochs/20) == 0:\n",
    "#             animator.add(epoch +1, (avg_loss, avg_vloss))\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            torch.save(net, \"model_best_state\")\n",
    "    model = torch.load(\"model_best_state\")\n",
    "    pred = model(X_val).detach().numpy()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc9156ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... finished running iter 1\n",
      "... finished running iter 2\n",
      "... finished running iter 3\n",
      "... finished running iter 4\n",
      "... finished running iter 5\n",
      "... finished running iter 6\n",
      "... finished running iter 7\n",
      "... finished running iter 8\n",
      "... finished running iter 9\n",
      "... finished running iter 10\n",
      "... finished running iter 11\n",
      "... finished running iter 12\n",
      "... finished running iter 13\n",
      "... finished running iter 14\n",
      "... finished running iter 15\n",
      "... finished running iter 16\n",
      "... finished running iter 17\n",
      "... finished running iter 18\n",
      "... finished running iter 19\n",
      "... finished running iter 20\n",
      "... finished running iter 21\n",
      "... finished running iter 22\n",
      "... finished running iter 23\n",
      "... finished running iter 24\n",
      "... finished running iter 25\n",
      "... finished running iter 26\n",
      "... finished running iter 27\n",
      "... finished running iter 28\n",
      "... finished running iter 29\n",
      "... finished running iter 30\n"
     ]
    }
   ],
   "source": [
    "#Iterate \n",
    "cl,tl,x,icp,mil = [],[],[],[[] for _ in range(qlen//2)],[[] for _ in range(qlen//2)]\n",
    "for k in range(num_iter):\n",
    "    net = init()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr = lr)\n",
    "    pred = iter()\n",
    "    cl.append(crossing_loss(pred))\n",
    "    tl.append(tilted_loss(quantiles,Y_val,pred))\n",
    "    x.append(eval_error(Y_val,pred))\n",
    "    print(\"... finished running iter\",k+1)\n",
    "    for i in range(qlen//2):\n",
    "        t1,t2 = eval_quantiles(pred[:,:,i+1],pred[:,:,qlen-i],Y_val)\n",
    "        icp[i].append(t1)\n",
    "        mil[i].append(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cb3728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate Errors\n",
    "def print_error():\n",
    "    print(\"Crossing Loss:\", np.mean([y[0] for y in cl]), \", Number of Cross:\", np.mean([y[1] for y in cl]))\n",
    "    print(\"MSE:\",np.mean([y[0] for y in x]), \"RMSE:\", np.mean([y[1] for y in x]),\"MAE:\", np.mean([y[2] for y in x]))\n",
    "    print(\"Tilted loss:\", np.mean(tl))\n",
    "    print(\"Prediction Intervals:\")\n",
    "    for i in range(qlen//2):\n",
    "        print(round((quantiles[qlen-i-1]-quantiles[i])*100),\"% ICP & MIL:\",round(np.mean(icp[i]),6),round(np.mean(mil[i]),6))\n",
    "#Test data will be touched after everything is done i.e. tuning hyperparameters & adjusting model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12b7f2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossing Loss: 0.01142637965704004 , Number of Cross: 13664.066666666668\n",
      "MSE: 4.6434194e-05 RMSE: 0.0068142 MAE: 0.004099001\n",
      "Tilted loss: 0.18683090907335279\n",
      "Prediction Intervals:\n",
      "90 % ICP & MIL: 0.944009 0.022674\n",
      "80 % ICP & MIL: 0.84536 0.015061\n",
      "60 % ICP & MIL: 0.627923 0.008433\n",
      "40 % ICP & MIL: 0.416744 0.004817\n",
      "20 % ICP & MIL: 0.221333 0.002194\n"
     ]
    }
   ],
   "source": [
    "print_error()\n",
    "#RMSE & MAE are always higher than errors of dummy prediction, tilted loss is lower "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b45d50ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy Prediction for Comparison\n",
    "cl,tl,x,icp,mil = [],[],[],[[] for _ in range(qlen//2)],[[] for _ in range(qlen//2)]\n",
    "p = np.array([[[0 for _ in range(pred.shape[2])] for _ in range(pred.shape[1])] for _ in range(pred.shape[0])])\n",
    "cl.append(crossing_loss(p))\n",
    "tl.append(tilted_loss(quantiles,Y_val,p))\n",
    "x.append(eval_error(Y_val,p))\n",
    "for i in range(qlen//2):\n",
    "    t1,t2 = eval_quantiles(p[:,:,i+1],p[:,:,qlen-i],Y_val)\n",
    "    icp[i].append(t1)\n",
    "    mil[i].append(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845b6f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossing Loss: 0.0 , Number of Cross: 0.0\n",
      "MSE: 4.343471827510494e-05 RMSE: 0.00659050212617407 MAE: 0.0036727230039435275\n",
      "Tilted loss: 0.25709061027604696\n",
      "Prediction Intervals:\n",
      "90 % ICP & MIL: 0.0 0.0\n",
      "80 % ICP & MIL: 0.0 0.0\n",
      "60 % ICP & MIL: 0.0 0.0\n",
      "40 % ICP & MIL: 0.0 0.0\n",
      "20 % ICP & MIL: 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print_error()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
